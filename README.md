# ğŸ¬ Multimodal Marvel Movie Recommendation System  
ğŸš€ *AI-powered RAG system for multimodal search with Weaviate*  

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)  
![Weaviate](https://img.shields.io/badge/Weaviate-VectorDB-orange?logo=weaviate)  
![FastAPI](https://img.shields.io/badge/API-FastAPI-teal?logo=fastapi)  
![License](https://img.shields.io/badge/License-MIT-green)  

---

## ğŸ“– Overview  

This project is an **AI-based multimodal recommendation system** for **Marvel movies**, built with **Weaviate Vector Database** and **Retrieval-Augmented Generation (RAG)**.  

It allows searching for movies using **text, image, audio, or video queries** and returns the most relevant results with embeddings stored in **Weaviate**.  

âœ¨ The goal is to show how **multimodal RAG** can be applied to build smart, context-aware recommendation systems.  

---

## âœ¨ Key Features  

- ğŸ” **Text Search** â†’ Search using natural language queries  
- ğŸ–¼ï¸ **Image Search** â†’ Upload posters or screenshots  
- ğŸ§ **Audio Search** â†’ Query using voice (speech-to-text pipeline)  
- ğŸ¥ **Video Search** â†’ Frame-based video similarity search  
- âš¡ **Weaviate Integration** â†’ Store and query embeddings efficiently  
- ğŸ“Š Dataset of Marvel movies with posters & metadata  

---

## ğŸ› ï¸ Tech Stack  

- **Language**: Python 3.11+  
- **Database**: [Weaviate](https://weaviate.io/) (Vector Database)  
- **Embeddings**: Cohere / OpenAI / CLIP  
- **Frameworks**: FastAPI (backend), Streamlit/Gradio (optional UI)  
- **ML Libraries**: PyTorch, Transformers  
- **Data**: Marvel movie posters + metadata CSV  

---


## ğŸ“‚ Project Structure

```
Multimodel_Movies_Search/
â”‚â”€â”€ assets/
â”‚ â”œâ”€â”€ movie_posters/ # Marvel movie posters dataset
â”‚ â”œâ”€â”€ test/ # Test data & screenshots
â”‚ â””â”€â”€ movies_with_local_posters.csv # Movie metadata with posters
â”‚
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ routes/ # API routes
â”‚ â”‚ â”œâ”€â”€ base.py
â”‚ â”‚ â”œâ”€â”€ image_search.py # Image search endpoint
â”‚ â”‚ â”œâ”€â”€ text_search.py # Text search endpoint
â”‚ â”‚ â””â”€â”€ schemas/ # Request/response schemas
â”‚ â”‚ â”œâ”€â”€ ImageRequest.py
â”‚ â”‚ â”œâ”€â”€ TextSearch.py
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ service/ # Business logic layer
â”‚ â”‚ â”œâ”€â”€ llm_multimodel.py
â”‚ â”‚ â”œâ”€â”€ MultimodelPipeline.py
â”‚ â”‚ â”œâ”€â”€ search_by_image.py
â”‚ â”‚ â”œâ”€â”€ search_by_text.py
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ stores/ # Vector DB connectors
â”‚ â”‚ â”œâ”€â”€ VectordbWeaviate.py
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/ # Utilities
â”‚ â”‚ â”œâ”€â”€ data_utils.py
â”‚ â”‚ â”œâ”€â”€ encode_utils.py
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ helper/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â””â”€â”€ config.py
â”‚ â”‚
â”‚ â”œâ”€â”€ main.py # Entry point (FastAPI app)
â”‚ â”œâ”€â”€ logger.py
â”‚ 
â”‚â”€â”€ requirements.txt # Project dependencies
â”‚â”€â”€ README.md # Project documentation
â”‚â”€â”€ .env.example # Example env variables
â”‚â”€â”€ .env # (your local env variables)
â”‚â”€â”€ test.py # Quick test script
â”‚â”€â”€ .gitignore # Git ignore file

```
## ğŸ–¼ï¸ Data Collection & Ingestion

Movie data and posters were collected automatically using a **custom Data Ingestion pipeline** powered by the [TMDB API](https://developer.themoviedb.org/).

### Features:
- Fetches movie metadata (ID, Title, Overview, Poster).
- Downloads and saves posters locally under `assets/movie_posters/`.
- Stores metadata in `assets/movies_with_local_posters.csv`.
- Ensures filenames are safe and consistent across OS.
- Easily configurable for different **genres** and **keywords** (default: Action + Sci-Fi + Superhero).

## âš™ï¸ Installation & Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/omarsabri125/Multimodel_Movies_Search.git
   cd Multimodel_Movies_Search
   ```

2. **Create and activate virtual environment**:
   ```bash
   python -m venv myenv
   source myenv/bin/activate   # Linux/Mac
   myenv\Scripts\activate      # Windows
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables** in `.env`:
   ```env
   COHERE_API_KEY=your_key_here
   OPENAI_API_KEY=your_key_here
   WEAVIATE_URL=https://your-weaviate-instance.weaviate.network
   ```
5. **Install Frontend Dependencies (Node.js)**

   Make sure Node.js is installed: https://nodejs.org
   Then, go to the frontend folder and install the packages:

   ```bash
   cd frontend
   npm install
   npm run dev
   ```
   
6. **Run the application**:
   ```bash
   uvicorn src.main:app --reload
   ```

---

## ğŸš€ Usage Examples

### ğŸ” Text Search
```http
POST /search_by_text
Content-Type: application/json

{
  "query": "superhero with iron suit"
}
```

### ğŸ–¼ï¸ Image Search
```bash
curl -X POST "http://localhost:8000//search_by_image" \
  -F "file=@assets/test/ironman_poster.jpg"
```

### ğŸ§ Audio Search
1. Record a voice query â†’ convert to text via Speech-to-Text.  
2. Send query to `/search_by_text`.

### ğŸ¥ Video Search
- Upload a video clip â†’ system extracts frames â†’ runs similarity search.  

---



